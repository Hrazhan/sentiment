{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296cb226",
   "metadata": {},
   "source": [
    "### Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fb2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import mplcairo\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"module://mplcairo.qt\")\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1e979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ناشرینترین کەس ئەو کەسەیە کە هەڵەکانت تۆمار دە...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ئیمڕۆ هاوکارەکەم وتی تەک مناڵەکانا چووگین بۆ د...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>بە خۆر بڵێ کیس و شت نەکا وە با، مانگیش شەوانە ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ئیشێ من ئەوەیە هەموو ڕۆژێ لە خەوێ‌ هەستم برێم:...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ئەرێ ئێوەش ئاوان؟ لە ماڵەوە بێزارن و و کە دەچی...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "2  ناشرینترین کەس ئەو کەسەیە کە هەڵەکانت تۆمار دە...  negative\n",
       "3  ئیمڕۆ هاوکارەکەم وتی تەک مناڵەکانا چووگین بۆ د...  negative\n",
       "4  بە خۆر بڵێ کیس و شت نەکا وە با، مانگیش شەوانە ...   neutral\n",
       "5  ئیشێ من ئەوەیە هەموو ڕۆژێ لە خەوێ‌ هەستم برێم:...  negative\n",
       "6  ئەرێ ئێوەش ئاوان؟ لە ماڵەوە بێزارن و و کە دەچی...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = pd.read_csv(\"./data/data.tsv\", sep='\\t')\n",
    "gold_df = gold_df[['tweet', 'sentiment']]\n",
    "# drop records where sentiment is none or mixed\n",
    "gold_df = gold_df.drop(gold_df[gold_df.sentiment == 'mixed'].index)\n",
    "gold_df = gold_df.drop(gold_df[gold_df.sentiment == 'none'].index)\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcaf1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df = pd.read_csv('./data/silver_data.csv')\n",
    "neu_aug = silver_df[silver_df.sentiment == 'neutral'].sample(700 - 254)\n",
    "pos_aug = silver_df[silver_df.sentiment == 'positive'].sample(700 - 292)\n",
    "neg_aug = silver_df[silver_df.sentiment == 'negative'].sample(700 - 639)\n",
    "df = pd.concat([neu_aug, pos_aug, neg_aug, gold_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce959b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df from gold_df index starts from 0\n",
    "# df = gold_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bf42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['tweet'].apply(lambda x:clean_text(x, lemma=True, emoji=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b2e936",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>حالیەن عیدەی من بەمیشکم دەری بەتاڵم😁</td>\n",
       "      <td>neutral</td>\n",
       "      <td>حالیەن عیدەی من بەمیشکم دەری بەتاڵم😁</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ئەوە قسەی دڵی بەلووچ نیە بەڵام ، لەبەر ئەوە سا...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ئەوە قسە دڵ بەلووچ نیە بەڵا لەبەر ئەوە سانسوور...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>دەڵێن مللەتی ئیران. کەنداو؛ کەنداوی فارسیە پشی...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>دەڵ مللەت ئیران کەنداو؛ کەنداوی فارسیە پشیلە پ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>دەی کاکە تو ئەۆ خۆدایە ئەگەر ئاگاداری لە بنەما...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>دەی کاکە تو ئەۆ خۆدایە ئەگەر ئاگاداری لە بنەما...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سیمینار لەسەر خەو و خواردن دەکا بەو سعات سێیەی🥲</td>\n",
       "      <td>neutral</td>\n",
       "      <td>سیمین لەسەر خەواندن و خواردن دەکا بەو سعات سێیەی🥲</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0               حالیەن عیدەی من بەمیشکم دەری بەتاڵم😁   neutral   \n",
       "1  ئەوە قسەی دڵی بەلووچ نیە بەڵام ، لەبەر ئەوە سا...   neutral   \n",
       "2  دەڵێن مللەتی ئیران. کەنداو؛ کەنداوی فارسیە پشی...   neutral   \n",
       "3  دەی کاکە تو ئەۆ خۆدایە ئەگەر ئاگاداری لە بنەما...   neutral   \n",
       "4    سیمینار لەسەر خەو و خواردن دەکا بەو سعات سێیەی🥲   neutral   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0               حالیەن عیدەی من بەمیشکم دەری بەتاڵم😁  \n",
       "1  ئەوە قسە دڵ بەلووچ نیە بەڵا لەبەر ئەوە سانسوور...  \n",
       "2  دەڵ مللەت ئیران کەنداو؛ کەنداوی فارسیە پشیلە پ...  \n",
       "3  دەی کاکە تو ئەۆ خۆدایە ئەگەر ئاگاداری لە بنەما...  \n",
       "4  سیمین لەسەر خەواندن و خواردن دەکا بەو سعات سێیەی🥲  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1136f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     700\n",
       "positive    700\n",
       "negative    700\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a591b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b367149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to balance the classes change the following variable\n",
    "num_of_categories = 1700\n",
    "\n",
    "shuffled = df.reindex(np.random.permutation(df.index))\n",
    "pos = shuffled[shuffled['sentiment'] == 'positive'][:num_of_categories]\n",
    "neg = shuffled[shuffled['sentiment'] == 'negative'][:num_of_categories]\n",
    "neu = shuffled[shuffled['sentiment'] == 'neutral'][:num_of_categories]\n",
    "concated = pd.concat([pos, neg, neu], ignore_index=True)\n",
    "concated['sentiment'] = concated['sentiment'].replace({'positive': 1, 'negative': -1, 'neutral': 0})\n",
    "#Shuffle the dataset\n",
    "concated = concated.reindex(np.random.permutation(concated.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d4669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52      1\n",
      "1090   -1\n",
      "546     1\n",
      "1996    0\n",
      "1740    0\n",
      "1989    0\n",
      "106     1\n",
      "1432    0\n",
      "1796    0\n",
      "131     1\n",
      "Name: sentiment, dtype: int64\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(concated['sentiment'][:10])\n",
    "labels = to_categorical(concated['sentiment'], num_classes=3)\n",
    "print(labels[:10])\n",
    "if 'sentiment' in concated.keys():\n",
    "    concated.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab3c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8907 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "n_most_common_words = 10000\n",
    "max_len = 300\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(concated['cleaned_text'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['cleaned_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ffc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1680, 300), (1680, 3), (420, 300), (420, 3))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.2, random_state=42)\n",
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f428354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dfea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5283cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:06:46.835582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.017744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.018385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.020266: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:06:47.022236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.022708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.022987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7392 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          890800    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 300, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300, 128)         84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,016,691\n",
      "Trainable params: 1,016,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size+1, output_dim=emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.25, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_m, precision_m, recall_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b4772dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 15s 2s/step - loss: 1.0886 - accuracy: 0.4459 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.0487 - val_accuracy: 0.5842 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0423 - accuracy: 0.5356 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.9888 - val_accuracy: 0.5842 - val_f1_m: 0.0503 - val_precision_m: 0.5556 - val_recall_m: 0.0263\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0090 - accuracy: 0.5356 - f1_m: 0.4083 - precision_m: 0.5585 - recall_m: 0.3811 - val_loss: 0.9731 - val_accuracy: 0.5842 - val_f1_m: 0.5842 - val_precision_m: 0.5842 - val_recall_m: 0.5842\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0146 - accuracy: 0.5356 - f1_m: 0.5357 - precision_m: 0.5357 - recall_m: 0.5357 - val_loss: 0.9700 - val_accuracy: 0.5842 - val_f1_m: 0.5842 - val_precision_m: 0.5842 - val_recall_m: 0.5842\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0012 - accuracy: 0.5356 - f1_m: 0.5400 - precision_m: 0.5444 - recall_m: 0.5358 - val_loss: 0.9784 - val_accuracy: 0.5842 - val_f1_m: 0.5460 - val_precision_m: 0.5799 - val_recall_m: 0.5158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.9936 - accuracy: 0.5356 - f1_m: 0.5510 - precision_m: 0.6938 - recall_m: 0.4609 - val_loss: 0.9790 - val_accuracy: 0.5842 - val_f1_m: 0.4416 - val_precision_m: 0.5763 - val_recall_m: 0.3579\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.9851 - accuracy: 0.5356 - f1_m: 0.5858 - precision_m: 0.7420 - recall_m: 0.4842 - val_loss: 0.9731 - val_accuracy: 0.5842 - val_f1_m: 0.5546 - val_precision_m: 0.5928 - val_recall_m: 0.5211\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9707 - accuracy: 0.5356 - f1_m: 0.5815 - precision_m: 0.6489 - recall_m: 0.5277 - val_loss: 0.9659 - val_accuracy: 0.5842 - val_f1_m: 0.5813 - val_precision_m: 0.5892 - val_recall_m: 0.5737\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9471 - accuracy: 0.5356 - f1_m: 0.5632 - precision_m: 0.5941 - recall_m: 0.5353 - val_loss: 0.9604 - val_accuracy: 0.5842 - val_f1_m: 0.5820 - val_precision_m: 0.5851 - val_recall_m: 0.5789\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9129 - accuracy: 0.5356 - f1_m: 0.5603 - precision_m: 0.5884 - recall_m: 0.5350 - val_loss: 0.9565 - val_accuracy: 0.5842 - val_f1_m: 0.5753 - val_precision_m: 0.5879 - val_recall_m: 0.5632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=8, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0ebf690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 109ms/step - loss: 1.0217 - accuracy: 0.5148 - f1_m: 0.5095 - precision_m: 0.5141 - recall_m: 0.5051\n",
      "Test set\n",
      "  Loss: 1.022\n",
      "  Accuracy: 0.515\n",
      "  F1:0.509\n",
      "  Precision: 0.514\n",
      "  Recall: 0.505 \n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test, y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n  F1:{:0.3f}\\n  Precision: {:0.3f}\\n  Recall: {:0.3f} '\n",
    "      .format(accr[0], accr[1], accr[2], accr[3], accr[4]))\n",
    "# note different emb dimension only increased training acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31849ff",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e208a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "جوان 🥀🌟 ئەوەیە بە ناو خەڵکدا بڕۆی بۆنی ئەخلاقت لێ بێت.🙂 positive\n",
      "بە ڕاستی ژیان ناخۆشە لێرە🖤 positive\n",
      "زەوی تەختە نەک خڕ گۆشە neutral\n"
     ]
    }
   ],
   "source": [
    "samples = [\"جوان 🥀🌟 ئەوەیە بە ناو خەڵکدا بڕۆی بۆنی ئەخلاقت لێ بێت.🙂\", \"بە ڕاستی ژیان ناخۆشە لێرە🖤\", \"زەوی تەختە نەک خڕ گۆشە\"]\n",
    "\n",
    "for sample in samples:\n",
    "    seq = tokenizer.texts_to_sequences([sample])\n",
    "    padded = pad_sequences(seq, maxlen=max_len)\n",
    "    pred = model.predict(padded, verbose=0)\n",
    "    labels = ['neutral', 'positive', 'negative']\n",
    "    print(sample, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f25ede",
   "metadata": {},
   "source": [
    "\n",
    "# Reference\n",
    "\n",
    "   - https://www.kaggle.com/code/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model\n",
    "   - https://www.kaggle.com/code/ngyptr/multi-class-classification-with-lstm\n",
    "   - https://www.dataknowsall.com/multiclass.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e190aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fd057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
