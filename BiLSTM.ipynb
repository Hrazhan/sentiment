{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296cb226",
   "metadata": {},
   "source": [
    "### Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7fb2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Bidirectional, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import mplcairo\n",
    "import matplotlib as mpl\n",
    "mpl.use(\"module://mplcairo.qt\")\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f1e979e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ù†Ø§Ø´Ø±ÛŒÙ†ØªØ±ÛŒÙ† Ú©Û•Ø³ Ø¦Û•Ùˆ Ú©Û•Ø³Û•ÛŒÛ• Ú©Û• Ù‡Û•ÚµÛ•Ú©Ø§Ù†Øª ØªÛ†Ù…Ø§Ø± Ø¯Û•...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¦ÛŒÙ…Ú•Û† Ù‡Ø§ÙˆÚ©Ø§Ø±Û•Ú©Û•Ù… ÙˆØªÛŒ ØªÛ•Ú© Ù…Ù†Ø§ÚµÛ•Ú©Ø§Ù†Ø§ Ú†ÙˆÙˆÚ¯ÛŒÙ† Ø¨Û† Ø¯...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø¨Û• Ø®Û†Ø± Ø¨ÚµÛ Ú©ÛŒØ³ Ùˆ Ø´Øª Ù†Û•Ú©Ø§ ÙˆÛ• Ø¨Ø§ØŒ Ù…Ø§Ù†Ú¯ÛŒØ´ Ø´Û•ÙˆØ§Ù†Û• ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ø¦ÛŒØ´Û Ù…Ù† Ø¦Û•ÙˆÛ•ÛŒÛ• Ù‡Û•Ù…ÙˆÙˆ Ú•Û†Ú˜Û Ù„Û• Ø®Û•ÙˆÛâ€Œ Ù‡Û•Ø³ØªÙ… Ø¨Ø±ÛÙ…:...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ø¦Û•Ø±Û Ø¦ÛÙˆÛ•Ø´ Ø¦Ø§ÙˆØ§Ù†ØŸ Ù„Û• Ù…Ø§ÚµÛ•ÙˆÛ• Ø¨ÛØ²Ø§Ø±Ù† Ùˆ Ùˆ Ú©Û• Ø¯Û•Ú†ÛŒ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment\n",
       "2  Ù†Ø§Ø´Ø±ÛŒÙ†ØªØ±ÛŒÙ† Ú©Û•Ø³ Ø¦Û•Ùˆ Ú©Û•Ø³Û•ÛŒÛ• Ú©Û• Ù‡Û•ÚµÛ•Ú©Ø§Ù†Øª ØªÛ†Ù…Ø§Ø± Ø¯Û•...  negative\n",
       "3  Ø¦ÛŒÙ…Ú•Û† Ù‡Ø§ÙˆÚ©Ø§Ø±Û•Ú©Û•Ù… ÙˆØªÛŒ ØªÛ•Ú© Ù…Ù†Ø§ÚµÛ•Ú©Ø§Ù†Ø§ Ú†ÙˆÙˆÚ¯ÛŒÙ† Ø¨Û† Ø¯...  negative\n",
       "4  Ø¨Û• Ø®Û†Ø± Ø¨ÚµÛ Ú©ÛŒØ³ Ùˆ Ø´Øª Ù†Û•Ú©Ø§ ÙˆÛ• Ø¨Ø§ØŒ Ù…Ø§Ù†Ú¯ÛŒØ´ Ø´Û•ÙˆØ§Ù†Û• ...   neutral\n",
       "5  Ø¦ÛŒØ´Û Ù…Ù† Ø¦Û•ÙˆÛ•ÛŒÛ• Ù‡Û•Ù…ÙˆÙˆ Ú•Û†Ú˜Û Ù„Û• Ø®Û•ÙˆÛâ€Œ Ù‡Û•Ø³ØªÙ… Ø¨Ø±ÛÙ…:...  negative\n",
       "6  Ø¦Û•Ø±Û Ø¦ÛÙˆÛ•Ø´ Ø¦Ø§ÙˆØ§Ù†ØŸ Ù„Û• Ù…Ø§ÚµÛ•ÙˆÛ• Ø¨ÛØ²Ø§Ø±Ù† Ùˆ Ùˆ Ú©Û• Ø¯Û•Ú†ÛŒ...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = pd.read_csv(\"./data/data.tsv\", sep='\\t')\n",
    "gold_df = gold_df[['tweet', 'sentiment']]\n",
    "# drop records where sentiment is none or mixed\n",
    "gold_df = gold_df.drop(gold_df[gold_df.sentiment == 'mixed'].index)\n",
    "gold_df = gold_df.drop(gold_df[gold_df.sentiment == 'none'].index)\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcaf1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df = pd.read_csv('./data/silver_data.csv')\n",
    "neu_aug = silver_df[silver_df.sentiment == 'neutral'].sample(700 - 254)\n",
    "pos_aug = silver_df[silver_df.sentiment == 'positive'].sample(700 - 292)\n",
    "neg_aug = silver_df[silver_df.sentiment == 'negative'].sample(700 - 639)\n",
    "df = pd.concat([neu_aug, pos_aug, neg_aug, gold_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce959b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new df from gold_df index starts from 0\n",
    "# df = gold_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73bf42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['tweet'].apply(lambda x:clean_text(x, lemma=True, emoji=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b2e936",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ø­Ø§Ù„ÛŒÛ•Ù† Ø¹ÛŒØ¯Û•ÛŒ Ù…Ù† Ø¨Û•Ù…ÛŒØ´Ú©Ù… Ø¯Û•Ø±ÛŒ Ø¨Û•ØªØ§ÚµÙ…ğŸ˜</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ø­Ø§Ù„ÛŒÛ•Ù† Ø¹ÛŒØ¯Û•ÛŒ Ù…Ù† Ø¨Û•Ù…ÛŒØ´Ú©Ù… Ø¯Û•Ø±ÛŒ Ø¨Û•ØªØ§ÚµÙ…ğŸ˜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ø¦Û•ÙˆÛ• Ù‚Ø³Û•ÛŒ Ø¯ÚµÛŒ Ø¨Û•Ù„ÙˆÙˆÚ† Ù†ÛŒÛ• Ø¨Û•ÚµØ§Ù… ØŒ Ù„Û•Ø¨Û•Ø± Ø¦Û•ÙˆÛ• Ø³Ø§...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ø¦Û•ÙˆÛ• Ù‚Ø³Û• Ø¯Úµ Ø¨Û•Ù„ÙˆÙˆÚ† Ù†ÛŒÛ• Ø¨Û•ÚµØ§ Ù„Û•Ø¨Û•Ø± Ø¦Û•ÙˆÛ• Ø³Ø§Ù†Ø³ÙˆÙˆØ±...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ø¯Û•ÚµÛÙ† Ù…Ù„Ù„Û•ØªÛŒ Ø¦ÛŒØ±Ø§Ù†. Ú©Û•Ù†Ø¯Ø§ÙˆØ› Ú©Û•Ù†Ø¯Ø§ÙˆÛŒ ÙØ§Ø±Ø³ÛŒÛ• Ù¾Ø´ÛŒ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ø¯Û•Úµ Ù…Ù„Ù„Û•Øª Ø¦ÛŒØ±Ø§Ù† Ú©Û•Ù†Ø¯Ø§ÙˆØ› Ú©Û•Ù†Ø¯Ø§ÙˆÛŒ ÙØ§Ø±Ø³ÛŒÛ• Ù¾Ø´ÛŒÙ„Û• Ù¾...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ø¯Û•ÛŒ Ú©Ø§Ú©Û• ØªÙˆ Ø¦Û•Û† Ø®Û†Ø¯Ø§ÛŒÛ• Ø¦Û•Ú¯Û•Ø± Ø¦Ø§Ú¯Ø§Ø¯Ø§Ø±ÛŒ Ù„Û• Ø¨Ù†Û•Ù…Ø§...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ø¯Û•ÛŒ Ú©Ø§Ú©Û• ØªÙˆ Ø¦Û•Û† Ø®Û†Ø¯Ø§ÛŒÛ• Ø¦Û•Ú¯Û•Ø± Ø¦Ø§Ú¯Ø§Ø¯Ø§Ø±ÛŒ Ù„Û• Ø¨Ù†Û•Ù…Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ø³ÛŒÙ…ÛŒÙ†Ø§Ø± Ù„Û•Ø³Û•Ø± Ø®Û•Ùˆ Ùˆ Ø®ÙˆØ§Ø±Ø¯Ù† Ø¯Û•Ú©Ø§ Ø¨Û•Ùˆ Ø³Ø¹Ø§Øª Ø³ÛÛŒÛ•ÛŒğŸ¥²</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Ø³ÛŒÙ…ÛŒÙ† Ù„Û•Ø³Û•Ø± Ø®Û•ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø®ÙˆØ§Ø±Ø¯Ù† Ø¯Û•Ú©Ø§ Ø¨Û•Ùˆ Ø³Ø¹Ø§Øª Ø³ÛÛŒÛ•ÛŒğŸ¥²</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet sentiment  \\\n",
       "0               Ø­Ø§Ù„ÛŒÛ•Ù† Ø¹ÛŒØ¯Û•ÛŒ Ù…Ù† Ø¨Û•Ù…ÛŒØ´Ú©Ù… Ø¯Û•Ø±ÛŒ Ø¨Û•ØªØ§ÚµÙ…ğŸ˜   neutral   \n",
       "1  Ø¦Û•ÙˆÛ• Ù‚Ø³Û•ÛŒ Ø¯ÚµÛŒ Ø¨Û•Ù„ÙˆÙˆÚ† Ù†ÛŒÛ• Ø¨Û•ÚµØ§Ù… ØŒ Ù„Û•Ø¨Û•Ø± Ø¦Û•ÙˆÛ• Ø³Ø§...   neutral   \n",
       "2  Ø¯Û•ÚµÛÙ† Ù…Ù„Ù„Û•ØªÛŒ Ø¦ÛŒØ±Ø§Ù†. Ú©Û•Ù†Ø¯Ø§ÙˆØ› Ú©Û•Ù†Ø¯Ø§ÙˆÛŒ ÙØ§Ø±Ø³ÛŒÛ• Ù¾Ø´ÛŒ...   neutral   \n",
       "3  Ø¯Û•ÛŒ Ú©Ø§Ú©Û• ØªÙˆ Ø¦Û•Û† Ø®Û†Ø¯Ø§ÛŒÛ• Ø¦Û•Ú¯Û•Ø± Ø¦Ø§Ú¯Ø§Ø¯Ø§Ø±ÛŒ Ù„Û• Ø¨Ù†Û•Ù…Ø§...   neutral   \n",
       "4    Ø³ÛŒÙ…ÛŒÙ†Ø§Ø± Ù„Û•Ø³Û•Ø± Ø®Û•Ùˆ Ùˆ Ø®ÙˆØ§Ø±Ø¯Ù† Ø¯Û•Ú©Ø§ Ø¨Û•Ùˆ Ø³Ø¹Ø§Øª Ø³ÛÛŒÛ•ÛŒğŸ¥²   neutral   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0               Ø­Ø§Ù„ÛŒÛ•Ù† Ø¹ÛŒØ¯Û•ÛŒ Ù…Ù† Ø¨Û•Ù…ÛŒØ´Ú©Ù… Ø¯Û•Ø±ÛŒ Ø¨Û•ØªØ§ÚµÙ…ğŸ˜  \n",
       "1  Ø¦Û•ÙˆÛ• Ù‚Ø³Û• Ø¯Úµ Ø¨Û•Ù„ÙˆÙˆÚ† Ù†ÛŒÛ• Ø¨Û•ÚµØ§ Ù„Û•Ø¨Û•Ø± Ø¦Û•ÙˆÛ• Ø³Ø§Ù†Ø³ÙˆÙˆØ±...  \n",
       "2  Ø¯Û•Úµ Ù…Ù„Ù„Û•Øª Ø¦ÛŒØ±Ø§Ù† Ú©Û•Ù†Ø¯Ø§ÙˆØ› Ú©Û•Ù†Ø¯Ø§ÙˆÛŒ ÙØ§Ø±Ø³ÛŒÛ• Ù¾Ø´ÛŒÙ„Û• Ù¾...  \n",
       "3  Ø¯Û•ÛŒ Ú©Ø§Ú©Û• ØªÙˆ Ø¦Û•Û† Ø®Û†Ø¯Ø§ÛŒÛ• Ø¦Û•Ú¯Û•Ø± Ø¦Ø§Ú¯Ø§Ø¯Ø§Ø±ÛŒ Ù„Û• Ø¨Ù†Û•Ù…Ø§...  \n",
       "4  Ø³ÛŒÙ…ÛŒÙ† Ù„Û•Ø³Û•Ø± Ø®Û•ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø®ÙˆØ§Ø±Ø¯Ù† Ø¯Û•Ú©Ø§ Ø¨Û•Ùˆ Ø³Ø¹Ø§Øª Ø³ÛÛŒÛ•ÛŒğŸ¥²  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1136f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     700\n",
       "positive    700\n",
       "negative    700\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a591b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RS = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b367149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to balance the classes change the following variable\n",
    "num_of_categories = 1700\n",
    "\n",
    "shuffled = df.reindex(np.random.permutation(df.index))\n",
    "pos = shuffled[shuffled['sentiment'] == 'positive'][:num_of_categories]\n",
    "neg = shuffled[shuffled['sentiment'] == 'negative'][:num_of_categories]\n",
    "neu = shuffled[shuffled['sentiment'] == 'neutral'][:num_of_categories]\n",
    "concated = pd.concat([pos, neg, neu], ignore_index=True)\n",
    "concated['sentiment'] = concated['sentiment'].replace({'positive': 1, 'negative': -1, 'neutral': 0})\n",
    "#Shuffle the dataset\n",
    "concated = concated.reindex(np.random.permutation(concated.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d4669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52      1\n",
      "1090   -1\n",
      "546     1\n",
      "1996    0\n",
      "1740    0\n",
      "1989    0\n",
      "106     1\n",
      "1432    0\n",
      "1796    0\n",
      "131     1\n",
      "Name: sentiment, dtype: int64\n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(concated['sentiment'][:10])\n",
    "labels = to_categorical(concated['sentiment'], num_classes=3)\n",
    "print(labels[:10])\n",
    "if 'sentiment' in concated.keys():\n",
    "    concated.drop(['sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bab3c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8907 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "n_most_common_words = 10000\n",
    "max_len = 300\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(concated['cleaned_text'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['cleaned_text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "vocab_size = len(word_index)\n",
    "\n",
    "X = pad_sequences(sequences, maxlen=max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95ffc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1680, 300), (1680, 3), (420, 300), (420, 3))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , labels, test_size=0.2, random_state=42)\n",
    "print((X_train.shape, y_train.shape, X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f428354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "emb_dim = 100\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dfea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5283cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:06:46.835582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.017744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.018385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.020266: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 19:06:47.022236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.022708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.022987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-09 19:06:47.807890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7392 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 300, 100)          890800    \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 300, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 300, 128)         84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               41216     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,016,691\n",
      "Trainable params: 1,016,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size+1, output_dim=emb_dim, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True, dropout=0.25, recurrent_dropout=0.1)))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',f1_m, precision_m, recall_m])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b4772dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 15s 2s/step - loss: 1.0886 - accuracy: 0.4459 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 1.0487 - val_accuracy: 0.5842 - val_f1_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_recall_m: 0.0000e+00\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0423 - accuracy: 0.5356 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00 - val_loss: 0.9888 - val_accuracy: 0.5842 - val_f1_m: 0.0503 - val_precision_m: 0.5556 - val_recall_m: 0.0263\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0090 - accuracy: 0.5356 - f1_m: 0.4083 - precision_m: 0.5585 - recall_m: 0.3811 - val_loss: 0.9731 - val_accuracy: 0.5842 - val_f1_m: 0.5842 - val_precision_m: 0.5842 - val_recall_m: 0.5842\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0146 - accuracy: 0.5356 - f1_m: 0.5357 - precision_m: 0.5357 - recall_m: 0.5357 - val_loss: 0.9700 - val_accuracy: 0.5842 - val_f1_m: 0.5842 - val_precision_m: 0.5842 - val_recall_m: 0.5842\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.0012 - accuracy: 0.5356 - f1_m: 0.5400 - precision_m: 0.5444 - recall_m: 0.5358 - val_loss: 0.9784 - val_accuracy: 0.5842 - val_f1_m: 0.5460 - val_precision_m: 0.5799 - val_recall_m: 0.5158\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.9936 - accuracy: 0.5356 - f1_m: 0.5510 - precision_m: 0.6938 - recall_m: 0.4609 - val_loss: 0.9790 - val_accuracy: 0.5842 - val_f1_m: 0.4416 - val_precision_m: 0.5763 - val_recall_m: 0.3579\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 4s 2s/step - loss: 0.9851 - accuracy: 0.5356 - f1_m: 0.5858 - precision_m: 0.7420 - recall_m: 0.4842 - val_loss: 0.9731 - val_accuracy: 0.5842 - val_f1_m: 0.5546 - val_precision_m: 0.5928 - val_recall_m: 0.5211\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9707 - accuracy: 0.5356 - f1_m: 0.5815 - precision_m: 0.6489 - recall_m: 0.5277 - val_loss: 0.9659 - val_accuracy: 0.5842 - val_f1_m: 0.5813 - val_precision_m: 0.5892 - val_recall_m: 0.5737\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9471 - accuracy: 0.5356 - f1_m: 0.5632 - precision_m: 0.5941 - recall_m: 0.5353 - val_loss: 0.9604 - val_accuracy: 0.5842 - val_f1_m: 0.5820 - val_precision_m: 0.5851 - val_recall_m: 0.5789\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9129 - accuracy: 0.5356 - f1_m: 0.5603 - precision_m: 0.5884 - recall_m: 0.5350 - val_loss: 0.9565 - val_accuracy: 0.5842 - val_f1_m: 0.5753 - val_precision_m: 0.5879 - val_recall_m: 0.5632\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',patience=8, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0ebf690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 109ms/step - loss: 1.0217 - accuracy: 0.5148 - f1_m: 0.5095 - precision_m: 0.5141 - recall_m: 0.5051\n",
      "Test set\n",
      "  Loss: 1.022\n",
      "  Accuracy: 0.515\n",
      "  F1:0.509\n",
      "  Precision: 0.514\n",
      "  Recall: 0.505 \n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test, y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}\\n  F1:{:0.3f}\\n  Precision: {:0.3f}\\n  Recall: {:0.3f} '\n",
    "      .format(accr[0], accr[1], accr[2], accr[3], accr[4]))\n",
    "# note different emb dimension only increased training acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31849ff",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e208a2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø¬ÙˆØ§Ù† ğŸ¥€ğŸŒŸ Ø¦Û•ÙˆÛ•ÛŒÛ• Ø¨Û• Ù†Ø§Ùˆ Ø®Û•ÚµÚ©Ø¯Ø§ Ø¨Ú•Û†ÛŒ Ø¨Û†Ù†ÛŒ Ø¦Û•Ø®Ù„Ø§Ù‚Øª Ù„Û Ø¨ÛØª.ğŸ™‚ positive\n",
      "Ø¨Û• Ú•Ø§Ø³ØªÛŒ Ú˜ÛŒØ§Ù† Ù†Ø§Ø®Û†Ø´Û• Ù„ÛØ±Û•ğŸ–¤ positive\n",
      "Ø²Û•ÙˆÛŒ ØªÛ•Ø®ØªÛ• Ù†Û•Ú© Ø®Ú• Ú¯Û†Ø´Û• neutral\n"
     ]
    }
   ],
   "source": [
    "samples = [\"Ø¬ÙˆØ§Ù† ğŸ¥€ğŸŒŸ Ø¦Û•ÙˆÛ•ÛŒÛ• Ø¨Û• Ù†Ø§Ùˆ Ø®Û•ÚµÚ©Ø¯Ø§ Ø¨Ú•Û†ÛŒ Ø¨Û†Ù†ÛŒ Ø¦Û•Ø®Ù„Ø§Ù‚Øª Ù„Û Ø¨ÛØª.ğŸ™‚\", \"Ø¨Û• Ú•Ø§Ø³ØªÛŒ Ú˜ÛŒØ§Ù† Ù†Ø§Ø®Û†Ø´Û• Ù„ÛØ±Û•ğŸ–¤\", \"Ø²Û•ÙˆÛŒ ØªÛ•Ø®ØªÛ• Ù†Û•Ú© Ø®Ú• Ú¯Û†Ø´Û•\"]\n",
    "\n",
    "for sample in samples:\n",
    "    seq = tokenizer.texts_to_sequences([sample])\n",
    "    padded = pad_sequences(seq, maxlen=max_len)\n",
    "    pred = model.predict(padded, verbose=0)\n",
    "    labels = ['neutral', 'positive', 'negative']\n",
    "    print(sample, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f25ede",
   "metadata": {},
   "source": [
    "\n",
    "# Reference\n",
    "\n",
    "   - https://www.kaggle.com/code/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model\n",
    "   - https://www.kaggle.com/code/ngyptr/multi-class-classification-with-lstm\n",
    "   - https://www.dataknowsall.com/multiclass.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e190aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5699ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fd057",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
